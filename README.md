# ğŸ”¬ EPISTEME NETWORK

Un outil interactif pour **gÃ©nÃ©rer, visualiser et analyser** les connexions entre scientifiques Ã  partir de leurs pages WikipÃ©dia, propulsÃ© par **EPISTEME NETWORK**.

## ğŸ“– Vue d'ensemble

**EPISTEME NETWORK : RÃ‰SEAU SCIENTIFIQUE â€” Pipeline Data & IA**

Cartographie des influences scientifiques : Un outil interactif propulsÃ© par l'IA qui connecte **~1 700 scientifiques** Ã  travers les siÃ¨cles (XIIe-XXIe) pour visualiser l'histoire des idÃ©es.

*   **Objectif** : GÃ©nÃ©rer automatiquement un graphe de connaissances Ã  partir de biographies non structurÃ©es (WikipÃ©dia).
*   **Architecture** : Pipeline ETL robuste combinant Scraping, **Extraction & Classification SÃ©mantique Multi-label** (Groq/Mistral) et ThÃ©orie des Graphes.
*   **Data Engineering** : StratÃ©gie de **Smart Caching** (MD5) pour optimiser les appels API. CrÃ©ation d'un "Golden Dataset" via nettoyage expert (Fuzzy Matching, Police Temporelle pour cohÃ©rence chronologique).
*   **Analyse & Visu** : DÃ©tection de communautÃ©s et calcul de centralitÃ© (PageRank) pour identifier les "Passeurs de Savoir". Visualisation interactive (PyVis/Sigma.js) avec moteur physique.

## ğŸŒŸ FonctionnalitÃ©s

### Extraction et Analyse

*   **Extraction automatique** : Analyse des pages WikipÃ©dia via LLM (Groq, OpenAI, Ollama, Mistral, Cerebras) pour trouver qui a influencÃ© qui.
*   **Prompt Few-Shot + Chain-of-Thought** : Prompts avancÃ©s avec exemples et raisonnement structurÃ© pour une meilleure prÃ©cision.
*   **Cache intelligent** : SystÃ¨me de cache avec versioning pour Ã©viter les appels LLM redondants.
*   **Validation Wikidata** : VÃ©rification croisÃ©e des relations extraites via l'API SPARQL de Wikidata.

### Visualisation Interactive

*   **Graphe dynamique** : Zoom, recherche, glisser-dÃ©poser des nÅ“uds.
*   **Filtres avancÃ©s** :
    *   Par **domaine scientifique** (Physique, MathÃ©matiques, Chimie, etc.)
    *   Par **Ã©poque** (curseurs pour annÃ©es de naissance/mort, 1400-2000)
*   **Chemin le plus court** : Animation "fourmis" pour visualiser le lien entre deux scientifiques.
*   **DonnÃ©es temporelles** : AnnÃ©es de naissance et mort affichÃ©es pour chaque scientifique.

### Algorithmes de Graphe

*   **PageRank** : Taille des nÅ“uds selon leur influence globale dans le rÃ©seau.
*   **DÃ©tection de communautÃ©s** : Couleurs selon les "Ã©coles de pensÃ©e" (algorithme de Louvain).
*   **Poids temporels** : Les arÃªtes sont pondÃ©rÃ©es selon la proximitÃ© temporelle des scientifiques liÃ©s.

### Analyse AvancÃ©e

*   **DÃ©tection des rÃ©volutionnaires** : Identification des "paradigm shifters" via l'analyse des trous structurels (constraint de Burt).
*   **PrÃ©diction de liens** : Suggestion de relations manquantes basÃ©e sur les mÃ©triques de similaritÃ© (Jaccard, Adamic-Adar).
*   **Comparaison des traditions** : Analyse comparative des diffÃ©rentes Ã©coles scientifiques (GrÃ¨ce Antique, LumiÃ¨res, etc.).

## ğŸš€ Installation

**PrÃ©-requis** : Python 3.9+

1.  **Cloner ou tÃ©lÃ©charger le dossier du projet.**

2.  **CrÃ©er un environnement virtuel (recommandÃ©) :**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # Linux/Mac
    # ou .venv\Scripts\activate  # Windows
    ```

3.  **Installer les dÃ©pendances :**
    ```bash
    pip install -r requirements.txt
    ```

## âš™ï¸ Configuration

Ouvrez le fichier `config.py` pour ajuster les paramÃ¨tres :

### Choix du LLM
| Variable | Fournisseur | Description |
|----------|-------------|-------------|
| `USE_GROQ = True` | Groq | RecommandÃ© (300+ tokens/s) |
| `USE_OLLAMA = True` | Ollama | ExÃ©cution locale gratuite |
| `USE_OPENAI = True` | OpenAI | GPT-3.5/4 |
| `USE_MISTRAL = True` | Mistral AI | Alternative europÃ©enne |
| `USE_CEREBRAS = True` | Cerebras | TrÃ¨s rapide |

### Limites du Graphe
*   `MAX_DEPTH` : Profondeur d'exploration depuis le point de dÃ©part (ex: 6).
*   `MAX_SCIENTISTS` : Nombre maximum de nÅ“uds (ex: 500).
*   `START_SCIENTIST` : Point de dÃ©part de l'exploration (ex: `"Albert Einstein"`).

## ğŸƒâ€â™‚ï¸ Utilisation

### GÃ©nÃ©ration du graphe
```bash
python3 main.py
```
*Le script va scanner WikipÃ©dia, interroger l'IA, et construire le graphe en temps rÃ©el.*

### Ouvrir la visualisation
Ouvrez simplement le fichier gÃ©nÃ©rÃ© dans votre navigateur :
```
output/index.html
```

### Scripts d'analyse avancÃ©e

```bash
# Enrichir avec les donnÃ©es temporelles
python3 scripts/enrich_temporal.py

# DÃ©tecter les rÃ©volutionnaires scientifiques
python3 scripts/paradigm_shifters.py

# PrÃ©dire les liens manquants
python3 scripts/link_prediction.py

# Comparer les traditions scientifiques
python3 scripts/tradition_analysis.py

# Valider les relations avec Wikidata
python3 validator.py
```

### Maintenance du graphe

```bash
# Supprimer les nÅ“uds isolÃ©s
python3 scripts/remove_isolated.py

# DÃ©dupliquer les nÅ“uds
python3 scripts/deduplicate_nodes.py

# Regrouper les domaines mineurs
python3 scripts/group_to_other.py

# Sauvegarder une version
python3 scripts/save_version.py "v2.0_description"
```

## ğŸ“‚ Structure du projet

```
.
â”œâ”€â”€ main.py                  # Orchestrateur principal
â”œâ”€â”€ config.py                # Configuration (LLM, limites, etc.)
â”œâ”€â”€ wikipedia_client.py      # RÃ©cupÃ©ration des textes WikipÃ©dia
â”œâ”€â”€ llm_extractor.py         # Extraction des relations via LLM
â”œâ”€â”€ graph_builder.py         # Construction du graphe NetworkX
â”œâ”€â”€ graph_analyzer.py        # PageRank, communautÃ©s, mÃ©triques
â”œâ”€â”€ visualizer.py            # GÃ©nÃ©ration HTML/JS interactive
â”œâ”€â”€ cache_manager.py         # Cache intelligent pour LLM
â”œâ”€â”€ validator.py             # Validation Wikidata
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ enrich_temporal.py       # Extraction des dates (naissance/mort)
â”‚   â”œâ”€â”€ paradigm_shifters.py     # Analyse des trous structurels
â”‚   â”œâ”€â”€ link_prediction.py       # PrÃ©diction de liens manquants
â”‚   â”œâ”€â”€ tradition_analysis.py    # Comparaison des traditions
â”‚   â”œâ”€â”€ deduplicate_nodes.py     # Fusion des doublons
â”‚   â”œâ”€â”€ filter_non_scientists.py # Nettoyage des non-scientifiques
â”‚   â”œâ”€â”€ remove_isolated.py       # Suppression des nÅ“uds isolÃ©s
â”‚   â”œâ”€â”€ group_to_other.py        # Regroupement des domaines mineurs
â”‚   â”œâ”€â”€ regenerate_viz.py        # RÃ©gÃ©nÃ©ration de la visualisation
â”‚   â””â”€â”€ save_version.py          # Sauvegarde avec versioning
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ index.html           # Visualisation interactive
â”‚   â”œâ”€â”€ about.html           # Page "Ã€ propos" du projet
â”‚   â””â”€â”€ scientist_graph.gexf # Graphe au format GEXF (Gephi)
â”‚
â”œâ”€â”€ saves/                   # Versions sauvegardÃ©es du graphe
â””â”€â”€ data/                    # Cache des rÃ©ponses LLM
```

## ğŸ“Š MÃ©triques du Graphe Actuel

| MÃ©trique | Valeur |
|----------|--------|
| **NÅ“uds** | ~1 726 scientifiques |
| **ArÃªtes** | ~2 520 relations d'influence |
| **PÃ©riode** | 1105 - 2006 (XIIe - XXIe siÃ¨cle) |
| **QualitÃ©** | 100% ConnectÃ© (Pas de nÅ“uds isolÃ©s) |
| **DonnÃ©e** | Enrichie (Domaines scientifiques identifiÃ©s par IA) |

## ğŸ› ï¸ Technologies

*   **Python 3.9+** avec NetworkX, Requests, Wikipedia-API
*   **LLM** : Groq (Llama 3), Ollama, OpenAI, Mistral, Cerebras
*   **Frontend** : vis-network.js, HTML5/CSS3/JavaScript
*   **APIs** : Wikipedia API, Wikidata SPARQL

## ğŸ“ Licence

Projet universitaire - MIASHS L3 - Graphes et Open Data

---

**Auteur** : Terrel Nuentsa  
**UniversitÃ©** : L3 MIASHS - Semestre 2
